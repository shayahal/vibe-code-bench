"""
Vulnerability Merger Agent

Intelligently merges and deduplicates vulnerabilities from multiple sources
(red team agent, static analysis) using LLM-based analysis.
"""

import json
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime

from vibe_code_bench.core.logging_setup import get_logger
from vibe_code_bench.core.llm_setup import initialize_llm
from langchain_anthropic import ChatAnthropic

logger = get_logger(__name__)


def _extract_found_vulnerabilities_from_red_team(red_team_result: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extract only found vulnerabilities from red team structured report.
    
    Args:
        red_team_result: Red team agent results
        
    Returns:
        List of found vulnerabilities
    """
    if not red_team_result:
        return []
    
    # Try to get structured report
    structured_report = red_team_result.get("structured_report")
    if not structured_report:
        # Fallback: try to load from file
        json_file = red_team_result.get("json_report_file")
        if json_file:
            json_path = Path(json_file)
            if json_path.exists():
                try:
                    with open(json_path, 'r') as f:
                        structured_report = json.load(f)
                except Exception as e:
                    logger.warning(f"Failed to load structured report from {json_path}: {e}")
        else:
            # Try to find structured JSON near the markdown report
            report_file = red_team_result.get("report_file")
            if report_file:
                report_path = Path(report_file)
                # Try same directory with _structured.json suffix
                json_path = report_path.parent / "red_team_structured.json"
                if json_path.exists():
                    try:
                        with open(json_path, 'r') as f:
                            structured_report = json.load(f)
                    except Exception as e:
                        logger.warning(f"Failed to load structured report from {json_path}: {e}")
    
    if not structured_report:
        return []
    
    # Extract only found vulnerabilities
    vulnerabilities = structured_report.get("vulnerabilities", [])
    found_vulns = [v for v in vulnerabilities if v.get("found", False)]
    
    # Normalize format
    normalized = []
    for vuln in found_vulns:
        normalized.append({
            "id": vuln.get("id", "UNKNOWN"),
            "name": vuln.get("name", "Unknown"),
            "severity": vuln.get("severity", "Medium"),
            "type": vuln.get("type", "Unknown"),
            "source": "red_team",
            "description": vuln.get("agent_description") or vuln.get("description", ""),
            "fix": vuln.get("fix", ""),
            "details": {}
        })
    
    return normalized


def _extract_vulnerabilities_from_static_analysis(static_analysis_result: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extract vulnerabilities from static analysis results.
    
    Args:
        static_analysis_result: Static analysis results
        
    Returns:
        List of vulnerabilities
    """
    if not static_analysis_result:
        return []
    
    vulnerabilities = static_analysis_result.get("vulnerabilities", [])
    
    # Normalize format
    normalized = []
    for vuln in vulnerabilities:
        normalized.append({
            "id": vuln.get("id", f"STATIC-{len(normalized) + 1:03d}"),
            "name": vuln.get("name") or vuln.get("description", "Unknown"),
            "severity": vuln.get("severity", "Medium"),
            "type": vuln.get("type", "Static Analysis"),
            "source": "static_analysis",
            "description": vuln.get("description", ""),
            "file": vuln.get("file"),
            "line": vuln.get("line"),
            "tool": vuln.get("tool"),
            "details": {
                "tool": vuln.get("tool"),
                "test_id": vuln.get("test_id"),
                "rule_id": vuln.get("rule_id"),
                "package": vuln.get("package")
            }
        })
    
    return normalized


def merge_vulnerabilities_with_agent(
    static_analysis_result: Optional[Dict[str, Any]],
    red_team_result: Optional[Dict[str, Any]],
    model_name: str = "anthropic/claude-3-haiku-20240307"
) -> Dict[str, Any]:
    """
    Merge vulnerabilities from multiple sources using LLM-based deduplication.
    
    Args:
        static_analysis_result: Static analysis results
        red_team_result: Red team agent results
        model_name: Model to use for merging
        
    Returns:
        Merged vulnerability report with deduplicated vulnerabilities
    """
    logger.info("Merging vulnerabilities with intelligent deduplication...")
    
    # Extract vulnerabilities from each source
    red_team_vulns = _extract_found_vulnerabilities_from_red_team(red_team_result)
    static_vulns = _extract_vulnerabilities_from_static_analysis(static_analysis_result)
    
    logger.info(f"Found {len(red_team_vulns)} vulnerabilities from red team")
    logger.info(f"Found {len(static_vulns)} vulnerabilities from static analysis")
    
    # If no vulnerabilities, return empty report
    if not red_team_vulns and not static_vulns:
        return {
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "total_vulnerabilities": 0,
                "sources": {}
            },
            "summary": {
                "total": 0,
                "by_severity": {"Critical": 0, "High": 0, "Medium": 0, "Low": 0},
                "by_source": {}
            },
            "vulnerabilities": [],
            "by_severity": {"Critical": [], "High": [], "Medium": [], "Low": []},
            "by_source": {}
        }
    
    # Use LLM to deduplicate and merge
    llm, _ = initialize_llm(
        provider="anthropic",
        model_name=model_name,
        temperature=0.3,
        api_key=None  # Will use ANTHROPIC_API_KEY env var
    )
    
    # Prepare input for LLM
    all_vulns = {
        "red_team": red_team_vulns,
        "static_analysis": static_vulns
    }
    
    prompt = f"""You are a security expert analyzing vulnerabilities from multiple sources. Your task is to merge and deduplicate vulnerabilities intelligently.

Red Team Vulnerabilities ({len(red_team_vulns)}):
{json.dumps(red_team_vulns, indent=2)}

Static Analysis Vulnerabilities ({len(static_vulns)}):
{json.dumps(static_vulns, indent=2)}

Analyze these vulnerabilities and:
1. Identify duplicates (same vulnerability reported by multiple sources)
2. Merge duplicates into a single entry, keeping the most detailed information
3. Preserve unique vulnerabilities from each source
4. Maintain severity levels (use the highest if different)
5. Keep source information (list all sources that found it)

Return a JSON object with this structure:
{{
  "vulnerabilities": [
    {{
      "id": "VULN-XXX or STATIC-XXX",
      "name": "Vulnerability name",
      "severity": "Critical|High|Medium|Low",
      "type": "Vulnerability type",
      "sources": ["red_team", "static_analysis"],
      "description": "Combined description",
      "details": {{}}
    }}
  ]
}}

Only include actual vulnerabilities - be conservative and only merge if they're clearly the same issue.
"""
    
    try:
        response = llm.invoke(prompt)
        content = response.content if hasattr(response, 'content') else str(response)
        
        # Extract JSON from response
        import re
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            merged_data = json.loads(json_match.group())
        else:
            # Fallback: try to parse entire response
            merged_data = json.loads(content)
        
        merged_vulns = merged_data.get("vulnerabilities", [])
        
    except Exception as e:
        logger.warning(f"LLM deduplication failed: {e}. Falling back to simple merge.")
        # Fallback: simple merge without deduplication
        merged_vulns = []
        seen_ids = set()
        
        # Add red team vulnerabilities
        for vuln in red_team_vulns:
            vuln_id = vuln.get("id")
            if vuln_id and vuln_id not in seen_ids:
                merged_vulns.append({**vuln, "sources": ["red_team"]})
                seen_ids.add(vuln_id)
        
        # Add static analysis vulnerabilities (check for duplicates by name/type)
        for vuln in static_vulns:
            vuln_id = vuln.get("id")
            # Check if similar vulnerability already exists
            is_duplicate = False
            for existing in merged_vulns:
                if (existing.get("name", "").lower() == vuln.get("name", "").lower() and
                    existing.get("type", "") == vuln.get("type", "")):
                    # Merge into existing
                    existing["sources"].append("static_analysis")
                    if vuln.get("severity") == "Critical" and existing.get("severity") != "Critical":
                        existing["severity"] = "Critical"
                    is_duplicate = True
                    break
            
            if not is_duplicate and vuln_id not in seen_ids:
                merged_vulns.append({**vuln, "sources": ["static_analysis"]})
                seen_ids.add(vuln_id)
    
    # Calculate summary statistics
    by_severity = {
        "Critical": [],
        "High": [],
        "Medium": [],
        "Low": []
    }
    
    for vuln in merged_vulns:
        severity = vuln.get("severity", "Medium")
        if severity in by_severity:
            by_severity[severity].append(vuln)
    
    # Group by source
    by_source = {}
    for vuln in merged_vulns:
        sources = vuln.get("sources", ["unknown"])
        for source in sources:
            if source not in by_source:
                by_source[source] = []
            by_source[source].append(vuln)
    
    # Count sources
    source_counts = {}
    for vuln in merged_vulns:
        sources = vuln.get("sources", ["unknown"])
        for source in sources:
            source_counts[source] = source_counts.get(source, 0) + 1
    
    merged_report = {
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "total_vulnerabilities": len(merged_vulns),
            "sources": source_counts
        },
        "summary": {
            "total": len(merged_vulns),
            "by_severity": {
                severity: len(vulns)
                for severity, vulns in by_severity.items()
            },
            "by_source": {
                source: len(vulns)
                for source, vulns in by_source.items()
            }
        },
        "vulnerabilities": merged_vulns,
        "by_severity": by_severity,
        "by_source": by_source
    }
    
    logger.info(f"Merged to {len(merged_vulns)} unique vulnerabilities:")
    logger.info(f"  By Severity: Critical={len(by_severity['Critical'])}, High={len(by_severity['High'])}, Medium={len(by_severity['Medium'])}, Low={len(by_severity['Low'])}")
    logger.info(f"  By Source: {source_counts}")
    
    return merged_report

